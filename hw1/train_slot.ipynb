{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj9SXUyUdSQB",
        "outputId": "1aee1bec-ac77-488d-a0af-c828fe096826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qP-EbtWkbVrk"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "import json\n",
        "import logging\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from random import random, seed\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "import os \n",
        "import tqdm\n",
        "import math\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = {\n",
        "    'seed': 520,      \n",
        "    'batch_size': 100,\n",
        "    'learning_rate':0.001,\n",
        "    'n_epochs':500,\n",
        "    'data_dir':  \"./drive/MyDrive/ADL_hw1/data/slot/\",   # Directory to the dataset\n",
        "    'glove_path': \"./drive/MyDrive/ADL_hw1/glove.840B.300d.txt\",   # Path to Glove Embedding\n",
        "    'word2vector_path': \"./gensim_glove.840B.300d.txt\",     # Directory to save the processed file \n",
        "    'save_path': './models/model.ckpt',  \n",
        "    'early_stop': 200,  \n",
        "    'valid_ratio': 0.2     \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCwCPEXueNIb",
        "outputId": "6192844c-8dca-4ba3-bbf5-1e2e8e0cd4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2196018 \n",
            " 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.utils_any2vec:duplicate word '����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������' in ./gensim_glove.840B.300d.txt, ignoring all but first\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def construct_word2vec(): \n",
        "\n",
        "    (count, dimensions) = glove2word2vec(config['glove_path'], config['word2vector_path'])\n",
        "    print(count, '\\n', dimensions)\n",
        "    model = KeyedVectors.load_word2vec_format(config['word2vector_path'], binary=False)\n",
        "\n",
        "    return model\n",
        "\n",
        "def read_json():\n",
        "\n",
        "    slots = [] \n",
        "    texts = []\n",
        "    testing = []\n",
        "    labels = set()\n",
        "   \n",
        "    maxi = 0\n",
        "\n",
        "    for split in [\"train\", \"eval\"]:\n",
        "\n",
        "        dataset_path = Path( config['data_dir'] + f\"{split}.json\")\n",
        "        dataset = json.loads(dataset_path.read_text())\n",
        "        logging.info(f\"Dataset loaded at {str(dataset_path.resolve())}\")\n",
        "\n",
        "        for instance in dataset: # makes train data\n",
        "             temp_text = []\n",
        "             temp_label = [] \n",
        "             for tag in instance[\"tags\"]:\n",
        "                if tag == \"O\":\n",
        "                  temp_label.append(tag)\n",
        "                  \n",
        "                else:\n",
        "                  temp_label.append(tag[2:])\n",
        "                  labels.add(tag[2:]) # makes set for intent2idx \n",
        "             \n",
        "             number_of_word = 0\n",
        "\n",
        "             for token in instance[\"tokens\"]:\n",
        "                 temp_text.append(token)\n",
        "                 number_of_word = number_of_word + 1 \n",
        "\n",
        "             if number_of_word> maxi : # for padding \n",
        "                  maxi = number_of_word\n",
        "\n",
        "             texts.append(temp_text)\n",
        "             slots.append(temp_label)\n",
        "\n",
        "    # make test data\n",
        "    dataset_path = Path( config['data_dir'] + \"test.json\")\n",
        "    dataset = json.loads(dataset_path.read_text())\n",
        "    logging.info(f\"Dataset loaded at {str(dataset_path.resolve())}\")\n",
        "\n",
        "    for instance in dataset: # makes test data\n",
        "             \n",
        "        temp = [] \n",
        "             \n",
        "        for token in instance[\"tokens\"]:\n",
        "            temp.append(token)\n",
        "\n",
        "        testing.append(temp)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    intent2idx = {'date': 1, 'last_name': 2, 'time': 3, 'people': 4, 'first_name': 5, 'O': 0}\n",
        "    # for reproduce \n",
        "\n",
        "    for num in range(len(slots)):\n",
        "      for id , tag in enumerate(slots[num]):\n",
        "        slots[num][id] = intent2idx[tag]\n",
        "    \n",
        "    \n",
        "   \n",
        "\n",
        "    return slots , texts , intent2idx , maxi ,testing\n",
        "\n",
        "\n",
        "\n",
        "train_tags , train_texts , intent2idx , maxi_text , test_text = read_json()\n",
        "glove = construct_word2vec()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrKGClgfdIdG",
        "outputId": "d85e7bf0-d012-4e89-c1ce-cee2462d7596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of sentence : 8244\n",
            "number of sentence : 3731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:73: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def Word2Vector(data_list, word2vec_model, maxi_len):\n",
        "    \"\"\"\n",
        "    look up word vectors\n",
        "    turn each word into its pretrained word vector\n",
        "    return a list of word vectors corresponding to each token in train.data\n",
        "    \"\"\"\n",
        "\n",
        "    suffixs = [\"’m\",\"'s\",\"’d\",\"'ll\",\"'ve\",\"’s\",\"s'\",\"'ve\",\"'m\",\"'\",\"'re\",\"’ll\",\"’re\",\"!\",\";\",\"]\",\"驴\"]\n",
        "    \n",
        "    v = word2vec_model.get_vector('king')\n",
        "    dim  = len(v)\n",
        "\n",
        "\n",
        "    x = []\n",
        "    n = 0\n",
        "    num = 0\n",
        "    \n",
        "\n",
        "    for sentence in data_list:\n",
        "\n",
        "      vecs = []\n",
        "      \n",
        "      for word in  sentence :\n",
        "\n",
        "        #word = lemmatizer.lemmatize(word)   not even better\n",
        "       \n",
        "        try:\n",
        "          for kk in suffixs :\n",
        "              word = word.replace(kk, '')\n",
        "\n",
        "          vec = word2vec_model.get_vector(word)\n",
        "          vecs.append(vec)\n",
        "          \n",
        "        except KeyError:  \n",
        "          \n",
        "          if \":\" in word:\n",
        "            vec = word2vec_model.get_vector(\"pm\")\n",
        "            vecs.append(vec)\n",
        "          elif \".\" in word:\n",
        "            vec = word2vec_model.get_vector(\"pm\")\n",
        "            vecs.append(vec)\n",
        "          elif \"/\" in word:\n",
        "            vec = word2vec_model.get_vector(\"february\")\n",
        "            vecs.append(vec)\n",
        "          elif \"pm\" in word:\n",
        "            vec = word2vec_model.get_vector(\"pm\")\n",
        "            vecs.append(vec)\n",
        "          #elif \n",
        "          elif \"august\" in word:\n",
        "            vec = word2vec_model.get_vector(\"february\")\n",
        "            vecs.append(vec)\n",
        "          else:\n",
        "            vec = word2vec_model.get_vector(\"name\")\n",
        "            vecs.append(vec)\n",
        "            #print(sentence)\n",
        "            #print(word)  \n",
        "            #print(num)     \n",
        "          pass\n",
        "      num = num+1\n",
        "\n",
        "\n",
        "      x.append(np.array(vecs))\n",
        "\n",
        "      \n",
        "\n",
        "      n += 1\n",
        "    print(\"number of sentence :\", n )\n",
        "\n",
        "    return np.array(x)\n",
        "\n",
        "\n",
        "#x_train, x_val, y_train, y_val = train_test_split( train_texts, train_tags , test_size=config[\"valid_ratio\"], random_state=config[\"seed\"])\n",
        "\n",
        "\n",
        "\n",
        "x_total = Word2Vector(train_texts, glove , maxi_text)\n",
        "#x_val = Word2Vector(x_val, glove , maxi_text)\n",
        "x_test = Word2Vector(test_text, glove , maxi_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5fqg1w-1wibh"
      },
      "outputs": [],
      "source": [
        "# pad length to the same\n",
        "\n",
        "x = pad_sequence([torch.from_numpy(np.array(x)) for x in x_total],batch_first = True).float()\n",
        "y = pad_sequence([torch.from_numpy(np.array(x)) for x in train_tags],batch_first = True).float()\n",
        "\n",
        "\n",
        "x_test = pad_sequence([torch.from_numpy(np.array(x)) for x in x_test],batch_first = True).float()\n",
        "\n",
        "\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split( x, y , test_size=config[\"valid_ratio\"], random_state=config[\"seed\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-taWZORTMic9"
      },
      "outputs": [],
      "source": [
        "def same_seed(seed): \n",
        "    '''Fixes random number generator seeds for reproducibility.'''\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def trainer(train_loader, valid_loader, model, config, device):\n",
        "\n",
        "    #criterion = nn.CrossEntropyLoss(reduction='mean') \n",
        "    criterion = nn.HuberLoss(reduction='mean', delta=1.0)\n",
        "  \n",
        "    optimizer = torch.optim.RAdam(model.parameters(), lr=config[\"learning_rate\"], betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "   \n",
        "  \n",
        "\n",
        "    if not os.path.isdir('./models'):\n",
        "        os.mkdir('./models') # Create directory of saving models.\n",
        "\n",
        "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # Set your model to train mode.\n",
        "        loss_record = []\n",
        "\n",
        "        # tqdm is a package to visualize your training progress.\n",
        "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
        "\n",
        "        for x, y in train_pbar:\n",
        "            optimizer.zero_grad()               # Set gradient to zero.\n",
        "            x, y = x.to(device), y.to(device)   # Move your data to device. \n",
        "            pred = model(x)        \n",
        "            \n",
        "            loss = criterion(pred, y)\n",
        "            loss.backward()                     # Compute gradient(backpropagation).\n",
        "            optimizer.step()                    # Update parameters.\n",
        "            step += 1\n",
        "            loss_record.append(loss.detach().item())\n",
        "            \n",
        "            # Display current epoch number and loss on tqdm progress bar.\n",
        "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
        "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
        "\n",
        "        \n",
        "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
        "        \n",
        "\n",
        "        model.eval() # Set your model to evaluation mode.\n",
        "        loss_record = []\n",
        "        for x, y in valid_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)                \n",
        "                loss = criterion(pred, y)\n",
        "\n",
        "            loss_record.append(loss.item())\n",
        "            \n",
        "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
        "\n",
        "        \n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
        "        \n",
        "\n",
        "        if mean_valid_loss < best_loss:\n",
        "            best_loss = mean_valid_loss\n",
        "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
        "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
        "            early_stop_count = 0\n",
        "        else: \n",
        "            early_stop_count += 1\n",
        "\n",
        "        if early_stop_count >= config['early_stop']:\n",
        "            print('\\nModel is not improving, so we halt the training session.')\n",
        "            return best_loss\n",
        "    return best_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "C4KpBS111Obs"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Data_Converter(Dataset):\n",
        "\n",
        "    def __init__(self, x, y=None):\n",
        "        if y is None:\n",
        "            self.y = y\n",
        "        else:\n",
        "            self.y = torch.FloatTensor(y)\n",
        "        self.x = torch.FloatTensor(x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.x[idx]\n",
        "        else:\n",
        "            return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = Data_Converter(x_train, y_train), \\\n",
        "                                            Data_Converter(x_val, y_val), \\\n",
        "                                            Data_Converter(x_test)\n",
        "                                            \n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-qXyZO06XUvj"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class My_Model(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, batch_first, drop=0.3):\n",
        "        super(My_Model, self).__init__()\n",
        "        self.GRU = torch.nn.GRU(\n",
        "            input_size,\n",
        "            hidden_size,\n",
        "            num_layers,\n",
        "            batch_first=batch_first,\n",
        "            dropout=drop,\n",
        "            bidirectional=True,\n",
        "        )\n",
        "       \n",
        "        self.fc = nn.Linear(hidden_size , 35)\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x =  [batch, sequence, channel] if batch_first else [sequence, batch, channel]\n",
        "        output, _ = self.GRU(x)\n",
        "        \n",
        "        y = _.mean(0)\n",
        "        #y = self.linear(y)\n",
        "        y =  self.fc(y)\n",
        "\n",
        "        # y = self.softmax(y) \n",
        "        return y\n",
        "\n",
        "same_seed(config['seed'])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = My_Model(input_size=len(x_train[0][0]), hidden_size = 300 ,num_layers = 3 ,batch_first = True).to(device) # put your model and data on the same computation device.\n",
        "best_loss = trainer(train_loader, valid_loader, model, config, device)\n",
        "print(\"best_loss :\" + str(best_loss))\n"
      ],
      "metadata": {
        "id": "aBDk78CbzsQa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "961af522-bbeb-4502-ccaf-0a1419bab957"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/500]: 100%|██████████| 66/66 [00:08<00:00,  8.01it/s, loss=0.0827]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500]: Train loss: 0.0915, Valid loss: 0.0879\n",
            "Saving model with loss 0.088...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [2/500]: 100%|██████████| 66/66 [00:08<00:00,  8.20it/s, loss=0.0784]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/500]: Train loss: 0.0818, Valid loss: 0.0772\n",
            "Saving model with loss 0.077...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [3/500]: 100%|██████████| 66/66 [00:08<00:00,  8.21it/s, loss=0.065]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/500]: Train loss: 0.0716, Valid loss: 0.0661\n",
            "Saving model with loss 0.066...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [4/500]: 100%|██████████| 66/66 [00:08<00:00,  8.20it/s, loss=0.0703]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/500]: Train loss: 0.0623, Valid loss: 0.0568\n",
            "Saving model with loss 0.057...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [5/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.0477]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/500]: Train loss: 0.0537, Valid loss: 0.0512\n",
            "Saving model with loss 0.051...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [6/500]: 100%|██████████| 66/66 [00:08<00:00,  8.21it/s, loss=0.0412]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/500]: Train loss: 0.0468, Valid loss: 0.0455\n",
            "Saving model with loss 0.046...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [7/500]: 100%|██████████| 66/66 [00:08<00:00,  8.16it/s, loss=0.0371]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/500]: Train loss: 0.0418, Valid loss: 0.0416\n",
            "Saving model with loss 0.042...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [8/500]: 100%|██████████| 66/66 [00:08<00:00,  8.19it/s, loss=0.0353]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/500]: Train loss: 0.0384, Valid loss: 0.0388\n",
            "Saving model with loss 0.039...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [9/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.0309]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/500]: Train loss: 0.0351, Valid loss: 0.0359\n",
            "Saving model with loss 0.036...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [10/500]: 100%|██████████| 66/66 [00:08<00:00,  8.19it/s, loss=0.0397]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/500]: Train loss: 0.0323, Valid loss: 0.0330\n",
            "Saving model with loss 0.033...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [11/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.033]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/500]: Train loss: 0.0295, Valid loss: 0.0317\n",
            "Saving model with loss 0.032...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [12/500]: 100%|██████████| 66/66 [00:08<00:00,  8.16it/s, loss=0.0298]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/500]: Train loss: 0.0276, Valid loss: 0.0318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [13/500]: 100%|██████████| 66/66 [00:08<00:00,  8.20it/s, loss=0.0371]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/500]: Train loss: 0.0259, Valid loss: 0.0284\n",
            "Saving model with loss 0.028...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [14/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.0297]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/500]: Train loss: 0.0234, Valid loss: 0.0273\n",
            "Saving model with loss 0.027...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [15/500]: 100%|██████████| 66/66 [00:08<00:00,  8.17it/s, loss=0.0261]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/500]: Train loss: 0.0212, Valid loss: 0.0246\n",
            "Saving model with loss 0.025...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [16/500]: 100%|██████████| 66/66 [00:08<00:00,  8.19it/s, loss=0.0187]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/500]: Train loss: 0.0197, Valid loss: 0.0234\n",
            "Saving model with loss 0.023...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [17/500]: 100%|██████████| 66/66 [00:08<00:00,  8.16it/s, loss=0.0211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/500]: Train loss: 0.0186, Valid loss: 0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [18/500]: 100%|██████████| 66/66 [00:08<00:00,  8.16it/s, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/500]: Train loss: 0.0174, Valid loss: 0.0226\n",
            "Saving model with loss 0.023...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [19/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.0184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/500]: Train loss: 0.0167, Valid loss: 0.0228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [20/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.0161]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/500]: Train loss: 0.0159, Valid loss: 0.0218\n",
            "Saving model with loss 0.022...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [21/500]: 100%|██████████| 66/66 [00:08<00:00,  8.19it/s, loss=0.0135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/500]: Train loss: 0.0149, Valid loss: 0.0224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [22/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.0138]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/500]: Train loss: 0.0153, Valid loss: 0.0202\n",
            "Saving model with loss 0.020...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [23/500]: 100%|██████████| 66/66 [00:08<00:00,  8.14it/s, loss=0.0209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/500]: Train loss: 0.0133, Valid loss: 0.0218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [24/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.0117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/500]: Train loss: 0.0133, Valid loss: 0.0206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [25/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.00893]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/500]: Train loss: 0.0132, Valid loss: 0.0201\n",
            "Saving model with loss 0.020...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [26/500]: 100%|██████████| 66/66 [00:08<00:00,  8.12it/s, loss=0.0105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/500]: Train loss: 0.0118, Valid loss: 0.0198\n",
            "Saving model with loss 0.020...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [27/500]: 100%|██████████| 66/66 [00:08<00:00,  8.14it/s, loss=0.0111]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/500]: Train loss: 0.0113, Valid loss: 0.0195\n",
            "Saving model with loss 0.020...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [28/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.0101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/500]: Train loss: 0.0108, Valid loss: 0.0194\n",
            "Saving model with loss 0.019...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [29/500]: 100%|██████████| 66/66 [00:08<00:00,  8.12it/s, loss=0.0111]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/500]: Train loss: 0.0100, Valid loss: 0.0189\n",
            "Saving model with loss 0.019...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [30/500]: 100%|██████████| 66/66 [00:08<00:00,  8.11it/s, loss=0.00973]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/500]: Train loss: 0.0097, Valid loss: 0.0196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [31/500]: 100%|██████████| 66/66 [00:08<00:00,  8.17it/s, loss=0.013]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/500]: Train loss: 0.0095, Valid loss: 0.0192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [32/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.0112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/500]: Train loss: 0.0096, Valid loss: 0.0188\n",
            "Saving model with loss 0.019...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [33/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.00622]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/500]: Train loss: 0.0084, Valid loss: 0.0181\n",
            "Saving model with loss 0.018...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [34/500]: 100%|██████████| 66/66 [00:08<00:00,  8.14it/s, loss=0.00754]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/500]: Train loss: 0.0081, Valid loss: 0.0178\n",
            "Saving model with loss 0.018...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [35/500]: 100%|██████████| 66/66 [00:08<00:00,  8.14it/s, loss=0.00971]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/500]: Train loss: 0.0084, Valid loss: 0.0193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [36/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.00733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/500]: Train loss: 0.0081, Valid loss: 0.0192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [37/500]: 100%|██████████| 66/66 [00:08<00:00,  8.11it/s, loss=0.00353]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/500]: Train loss: 0.0071, Valid loss: 0.0177\n",
            "Saving model with loss 0.018...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [38/500]: 100%|██████████| 66/66 [00:08<00:00,  8.16it/s, loss=0.00627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/500]: Train loss: 0.0063, Valid loss: 0.0175\n",
            "Saving model with loss 0.017...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [39/500]: 100%|██████████| 66/66 [00:08<00:00,  8.16it/s, loss=0.0063]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/500]: Train loss: 0.0062, Valid loss: 0.0178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [40/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.00771]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/500]: Train loss: 0.0059, Valid loss: 0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [41/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.00779]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/500]: Train loss: 0.0064, Valid loss: 0.0179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [42/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.00641]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/500]: Train loss: 0.0060, Valid loss: 0.0172\n",
            "Saving model with loss 0.017...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [43/500]: 100%|██████████| 66/66 [00:08<00:00,  8.17it/s, loss=0.0128]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/500]: Train loss: 0.0063, Valid loss: 0.0178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [44/500]: 100%|██████████| 66/66 [00:08<00:00,  8.13it/s, loss=0.00515]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/500]: Train loss: 0.0050, Valid loss: 0.0174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [45/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.00411]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/500]: Train loss: 0.0047, Valid loss: 0.0174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [46/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.0034]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/500]: Train loss: 0.0054, Valid loss: 0.0169\n",
            "Saving model with loss 0.017...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [47/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.00421]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/500]: Train loss: 0.0049, Valid loss: 0.0171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [48/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.0103]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/500]: Train loss: 0.0047, Valid loss: 0.0169\n",
            "Saving model with loss 0.017...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [49/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.00573]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/500]: Train loss: 0.0044, Valid loss: 0.0171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [50/500]: 100%|██████████| 66/66 [00:08<00:00,  8.16it/s, loss=0.00452]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/500]: Train loss: 0.0044, Valid loss: 0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [51/500]: 100%|██████████| 66/66 [00:08<00:00,  8.17it/s, loss=0.00977]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [51/500]: Train loss: 0.0046, Valid loss: 0.0178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [52/500]: 100%|██████████| 66/66 [00:08<00:00,  8.16it/s, loss=0.00391]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [52/500]: Train loss: 0.0054, Valid loss: 0.0174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [53/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.00494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [53/500]: Train loss: 0.0045, Valid loss: 0.0163\n",
            "Saving model with loss 0.016...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [54/500]: 100%|██████████| 66/66 [00:08<00:00,  8.13it/s, loss=0.00399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [54/500]: Train loss: 0.0041, Valid loss: 0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [55/500]: 100%|██████████| 66/66 [00:08<00:00,  8.12it/s, loss=0.00512]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [55/500]: Train loss: 0.0047, Valid loss: 0.0170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [56/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.00567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [56/500]: Train loss: 0.0042, Valid loss: 0.0180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [57/500]: 100%|██████████| 66/66 [00:08<00:00,  8.13it/s, loss=0.00212]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [57/500]: Train loss: 0.0050, Valid loss: 0.0173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [58/500]: 100%|██████████| 66/66 [00:08<00:00,  8.18it/s, loss=0.00559]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [58/500]: Train loss: 0.0050, Valid loss: 0.0181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [59/500]: 100%|██████████| 66/66 [00:08<00:00,  8.12it/s, loss=0.00727]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [59/500]: Train loss: 0.0055, Valid loss: 0.0171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [60/500]: 100%|██████████| 66/66 [00:08<00:00,  8.15it/s, loss=0.0027]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [60/500]: Train loss: 0.0046, Valid loss: 0.0182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [61/500]: 100%|██████████| 66/66 [00:08<00:00,  8.16it/s, loss=0.00376]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [61/500]: Train loss: 0.0042, Valid loss: 0.0169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [62/500]: 100%|██████████| 66/66 [00:08<00:00,  8.13it/s, loss=0.00193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [62/500]: Train loss: 0.0041, Valid loss: 0.0167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [63/500]: 100%|██████████| 66/66 [00:08<00:00,  8.14it/s, loss=0.00804]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [63/500]: Train loss: 0.0053, Valid loss: 0.0198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [64/500]: 100%|██████████| 66/66 [00:08<00:00,  8.16it/s, loss=0.0146]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [64/500]: Train loss: 0.0057, Valid loss: 0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [65/500]: 100%|██████████| 66/66 [00:08<00:00,  7.86it/s, loss=0.0025]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [65/500]: Train loss: 0.0047, Valid loss: 0.0165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [66/500]:  36%|███▋      | 24/66 [00:03<00:05,  7.83it/s, loss=0.0056]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-f3a9a491841c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMy_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put your model and data on the same computation device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_loss :\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-1e995b4eded5>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(train_loader, valid_loader, model, config, device)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# Update parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mloss_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Display current epoch number and loss on tqdm progress bar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "gwtya0dZ0azO"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def predict(test_loader, model, device):\n",
        "    model.eval() # Set your model to evaluation mode.\n",
        "    preds = []\n",
        "    for x in test_loader:\n",
        "        x = x.to(device)                   \n",
        "        with torch.no_grad():                   \n",
        "            pred = model(x)\n",
        "\n",
        "            preds.append(pred.detach().cpu())   \n",
        "\n",
        "    preds = torch.cat(preds, dim=0).numpy()  \n",
        "    return preds\n",
        "\n",
        "\n",
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "   \n",
        "    next = True\n",
        "    with open(file, 'w') as fp:\n",
        "        \n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tags'])\n",
        "        \n",
        "        for i , num in enumerate(preds):\n",
        "   \n",
        "          string = \"\"\n",
        "          for j, token in enumerate(num):\n",
        "            if token == 'O' :\n",
        "              next = True\n",
        "              if string==\"\":\n",
        "\n",
        "                string = string + token\n",
        "              else:\n",
        "                string = string + \" \"+ token\n",
        "            else:\n",
        "              if next == True:\n",
        "                if string==\"\":\n",
        "\n",
        "                  string = string + \"B-\"+str(token)\n",
        "                else:\n",
        "                  string = string + \" \"+ \"B-\"+str(token)\n",
        "                next = False\n",
        "\n",
        "              elif next == False:\n",
        "\n",
        "                if string==\"\":\n",
        "\n",
        "                  string = string + \"B-\"+str(token)\n",
        "                else:\n",
        "                  if num[j-1] == token:\n",
        "                    string = string + \" \"+ \"I-\"+str(token)\n",
        "                  else:\n",
        "                    string = string + \" \"+ \"B-\"+str(token)\n",
        "                \n",
        "          \n",
        "          writer.writerow([\"test-\"+str(i), string])\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "_JU6xIR9zn9Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "     \n",
        "\n",
        "\n",
        "model = My_Model(input_size=len(x_train[0][0]), hidden_size = 300 ,num_layers = 3 ,batch_first = True).to(device)\n",
        "model.load_state_dict(torch.load(config['save_path']))\n",
        "preds = predict(test_loader, model, device) \n",
        "final = []\n",
        "\n",
        "\n",
        "for id , sentence in enumerate(preds) :\n",
        "\n",
        "  temp_sentence = []\n",
        "  for i , item in enumerate(sentence):\n",
        "    \n",
        "    \n",
        "    if i < len(test_text[id]):\n",
        "\n",
        "\n",
        "      if item > 0.5 and item <1.5 :\n",
        "\n",
        "        temp_sentence.append(\"date\")\n",
        "\n",
        "      elif item > 1.5 and item <2.5 :\n",
        "\n",
        "        temp_sentence.append(\"last_name\")\n",
        "\n",
        "      elif item > 2.5 and item <3.5 :\n",
        "        \n",
        "        temp_sentence.append(\"time\")\n",
        "\n",
        "      elif item > 3.5 and item <4.5 :\n",
        "        \n",
        "        temp_sentence.append(\"people\")\n",
        "\n",
        "      elif item > 4.5  :\n",
        "       \n",
        "        temp_sentence.append(\"first_name\")\n",
        "\n",
        "      else:\n",
        "        temp_sentence.append(\"O\")\n",
        "    else:\n",
        "\n",
        "      break\n",
        "  final.append(temp_sentence)\n",
        "\n",
        "save_pred(final, 'pred.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yy = []\n",
        "for id , sentence in enumerate(y_val) :\n",
        "\n",
        "  temp_sentence = []\n",
        "  for i , item in enumerate(sentence):\n",
        "    \n",
        "    \n",
        "    if i < len(test_text[id]):\n",
        "\n",
        "\n",
        "      if item==1 :\n",
        "\n",
        "        temp_sentence.append(\"date\")\n",
        "\n",
        "      elif item ==2 :\n",
        "\n",
        "        temp_sentence.append(\"last_name\")\n",
        "\n",
        "      elif item ==3:\n",
        "        \n",
        "        temp_sentence.append(\"time\")\n",
        "\n",
        "      elif item ==4 :\n",
        "        \n",
        "        temp_sentence.append(\"people\")\n",
        "\n",
        "      elif item ==5  :\n",
        "       \n",
        "        temp_sentence.append(\"first_name\")\n",
        "\n",
        "      else:\n",
        "        temp_sentence.append(\"O\")\n",
        "    else:\n",
        "\n",
        "      break\n",
        "  yy.append(temp_sentence)"
      ],
      "metadata": {
        "id": "p3eGaPUnMBHe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(final).shape)\n",
        "print(yy[0])\n",
        "print(final[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XulGGaLQLgYa",
        "outputId": "c23cb663-0461-424d-d08a-bd86bbf40c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3731,)\n",
            "['O', 'O', 'O', 'time', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'people', 'people', 'O', 'time']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, valid_dataset, test_dataset = Data_Converter(x_train, y_train), \\\n",
        "                                            Data_Converter(x_val, y_val), \\\n",
        "                                            Data_Converter(x_test)\n",
        "                                            \n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "NA-qcGJqNApo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_val = predict(valid_loader, model, device)"
      ],
      "metadata": {
        "id": "5rwgng-PNEUn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = []\n",
        "\n",
        "\n",
        "for id , sentence in enumerate(pp_val) :\n",
        "\n",
        "  temp_sentence = []\n",
        "  for i , item in enumerate(sentence):\n",
        "    \n",
        "    \n",
        "    if i < len(test_text[id]):\n",
        "\n",
        "\n",
        "      if item > 0.5 and item <1.5 :\n",
        "\n",
        "        temp_sentence.append(\"date\")\n",
        "\n",
        "      elif item > 1.5 and item <2.5 :\n",
        "\n",
        "        temp_sentence.append(\"last_name\")\n",
        "\n",
        "      elif item > 2.5 and item <3.5 :\n",
        "        \n",
        "        temp_sentence.append(\"time\")\n",
        "\n",
        "      elif item > 3.5 and item <4.5 :\n",
        "        \n",
        "        temp_sentence.append(\"people\")\n",
        "\n",
        "      elif item > 4.5  :\n",
        "       \n",
        "        temp_sentence.append(\"first_name\")\n",
        "\n",
        "      else:\n",
        "        temp_sentence.append(\"O\")\n",
        "    else:\n",
        "\n",
        "      break\n",
        "  final.append(temp_sentence)"
      ],
      "metadata": {
        "id": "_VaTqq3TNyPh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(final[190]))\n",
        "print(len(yy[190]))\n",
        "\n",
        "f1_score(yy, final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R15BHAToN1pf",
        "outputId": "66170f44-b441-4b95-9db8-44e73a06f11e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: time seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: people seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: first_name seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: last_name seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7484662576687116"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "count_sentence = 0\n",
        "count_token = 0\n",
        "right_sentence =0\n",
        "right_token = 0 \n",
        "\n",
        "for id , sentence in enumerate(final) :\n",
        "  count_sentence = count_sentence + 1\n",
        "\n",
        "  if sentence == yy[id]:\n",
        "    right_sentence = right_sentence +1 \n",
        "\n",
        "  for i , item in enumerate(sentence):\n",
        "    count_token = count_token +1 \n",
        "    if item == yy[id][i]:\n",
        "        right_token = right_token +1\n",
        "\n",
        "\n",
        "print(\"Joint Accuracy : \" , right_sentence/count_sentence)\n",
        "print(\"Token Accuracy : \" , right_token / count_token )\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nQHucnXmaYd",
        "outputId": "a8b30cd1-107b-40e4-f799-b9aba1a82f45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joint Accuracy :  0.8611279563371741\n",
            "Token Accuracy :  0.9755653961727029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hw8BnlMiK_zT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ADL_hw1_Slot_tagging.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}